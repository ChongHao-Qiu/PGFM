{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "current_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "project_root = os.path.dirname(current_path)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from stage2_scripts.finetune import load_data as load_temp_data\n",
    "from stage3_scripts.finetune_do import load_data as load_do_data  \n",
    "from utils.utils import load_pd_data, combine_dataset\n",
    "\n",
    "# seed = 40\n",
    "\n",
    "ids = pd.read_csv('../utils/intersection_ids.csv')\n",
    "ids = ids['nhdhr_id'].to_list()\n",
    "\n",
    "label_names = 'obs_do'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(lake_id, model_type, datetime, stage, depth):\n",
    "    seed = 40\n",
    "    if model_type == 'transformer':\n",
    "        seed = 44\n",
    "    if stage == 3:\n",
    "        read_path = os.path.join(f'../stage{stage}_results/{model_type}/{datetime}/' + f'{lake_id}/{seed}', 'pred_test_raw.npy')\n",
    "    else:\n",
    "        read_path = os.path.join(f'../stage{stage}_results/{model_type}/{datetime}/' + f'{lake_id}/{seed}', 'pred_test.npy')\n",
    "    pred = np.load(read_path)\n",
    "\n",
    "    read_path = os.path.join(f'../stage{stage}_results/{model_type}/{datetime}/' + f'{lake_id}/{seed}', 'obs_test.npy')\n",
    "    obs = np.load(read_path)\n",
    "    read_path = os.path.join(f'../stage{stage}_results/{model_type}/{datetime}/' + f'{lake_id}/{seed}', 'sim_test.npy')\n",
    "    sim = np.load(read_path)\n",
    "    read_path = os.path.join(f'../stage{stage}_results/{model_type}/{datetime}/' + f'{lake_id}/{seed}', 'test_dates.npy')\n",
    "    dates = np.load(read_path)\n",
    "\n",
    "    indices = list(range(0, pred.shape[0], depth))\n",
    "    pred = pred[indices, :]\n",
    "    obs = obs[indices, :]\n",
    "    sim = sim[indices, :]\n",
    "    dates = dates[indices, :]\n",
    "\n",
    "\n",
    "    return pred, obs, sim, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import splprep, splev\n",
    "def smooth_boundary(points, hull, smoothing_factor=1):\n",
    "    hull_points = points[hull.vertices]\n",
    "    hull_points = np.append(hull_points, [hull_points[0]], axis=0)  # Close the loop\n",
    "    tck, u = splprep([hull_points[:, 0], hull_points[:, 1]], s=smoothing_factor, per=True)\n",
    "    unew = np.linspace(0, 1.0, 1000)\n",
    "    out = splev(unew, tck)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, MultiPoint\n",
    "from shapely.ops import cascaded_union, polygonize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "def alpha_shape(points, alpha):\n",
    "    \"\"\"\n",
    "    Compute the alpha shape (concave hull) of a set of points.\n",
    "    :param points: Iterable container of points.\n",
    "    :param alpha: Alpha value to influence the gooeyness of the border. Smaller\n",
    "                  numbers don't fall inward as much as larger numbers.\n",
    "    :return: List of (x, y) coordinates of the alpha shape.\n",
    "    \"\"\"\n",
    "    if len(points) < 4:\n",
    "        # When you have a triangle, there is no sense in computing an alpha shape.\n",
    "        return MultiPoint(list(points)).convex_hull\n",
    "    \n",
    "    def add_edge(edges, edge_points, coords, i, j):\n",
    "        \"\"\" Add a line between the i-th and j-th points, if not in the list already \"\"\"\n",
    "        if (i, j) in edges or (j, i) in edges:\n",
    "            # already added\n",
    "            return\n",
    "        edges.add( (i, j) )\n",
    "        edge_points.append(coords[ [i, j] ])\n",
    "    \n",
    "    coords = np.array([point for point in points])\n",
    "    tri = Delaunay(coords)\n",
    "    edges = set()\n",
    "    edge_points = []\n",
    "    # Loop over triangles:\n",
    "    # ia, ib, ic = indices of corner points of the triangle\n",
    "    for ia, ib, ic in tri.vertices:\n",
    "        pa = coords[ia]\n",
    "        pb = coords[ib]\n",
    "        pc = coords[ic]\n",
    "        \n",
    "        # Lengths of sides of triangle\n",
    "        a = np.linalg.norm(pa-pb)\n",
    "        b = np.linalg.norm(pb-pc)\n",
    "        c = np.linalg.norm(pc-pa)\n",
    "        \n",
    "        # Semiperimeter of the triangle\n",
    "        s = (a + b + c)/2.0\n",
    "        \n",
    "        # Area of the triangle by Heron's formula\n",
    "        area = np.sqrt(s*(s-a)*(s-b)*(s-c))\n",
    "        if area == 0:\n",
    "            circum_r = 0\n",
    "        else:\n",
    "            circum_r = a*b*c/(4.0*area)\n",
    "        \n",
    "        # Here's the radius filter.\n",
    "        if circum_r < 1.0/alpha:\n",
    "            add_edge(edges, edge_points, coords, ia, ib)\n",
    "            add_edge(edges, edge_points, coords, ib, ic)\n",
    "            add_edge(edges, edge_points, coords, ic, ia)\n",
    "    \n",
    "    m = MultiPoint([Point(point) for point in coords])\n",
    "    triangles = [Polygon(edge) for edge in polygonize(edge_points)]\n",
    "    return cascaded_union(triangles), edge_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, lake_id in enumerate(ids):\n",
    "    try:\n",
    "        if lake_id != 'nhdhr_120019016':\n",
    "            continue\n",
    "        test_pd_data = load_pd_data(\n",
    "            ids=[lake_id], dataset='test', save_path='../data/processedByLake/')['temp_data']\n",
    "        unique_depths = np.unique(test_pd_data['vertical_depth'])\n",
    "        n_depth = len(unique_depths)\n",
    "        print(\"n_depth:\", n_depth)\n",
    "        # temperature\n",
    "\n",
    "        lstm_pred_temp, obs_temp, sim_temp, dates_temp = get_data(lake_id, 'lstm', '2024-08-08-21-10', stage = 2, depth=n_depth)\n",
    "\n",
    "        pgfm_pred_temp, _, _, _ = get_data(lake_id, 'fm-pg', '2024-08-09-03-10', stage = 2, depth=n_depth)\n",
    "\n",
    "        ealstm_pred_temp, _, _, _ = get_data(lake_id, 'ealstm', '2024-08-10-22-30', stage = 2, depth=n_depth)\n",
    "        transformer_pred_temp, _, _, _ = get_data(lake_id, 'transformer', '2024-08-10-01-35', stage = 2, depth=n_depth)\n",
    "        \n",
    "        # oxygen\n",
    "        lstm_pred_do, obs_do, sim_do, dates_do = get_data(lake_id, 'lstm', '2024-08-09-23-00', stage = 3, depth=n_depth)\n",
    "\n",
    "        pgfm_pred_do, _, _, _ = get_data(lake_id, 'fm-pg', '2024-08-10-04-14', stage = 3, depth=n_depth)\n",
    "\n",
    "        ealstm_pred_do, _, _, _ = get_data(lake_id, 'ealstm', '2024-08-10-22-50', stage = 3, depth=n_depth)\n",
    "\n",
    "        transformer_pred_do, _, _, _ = get_data(lake_id, 'transformer', '2024-08-10-02-35', stage = 3, depth=n_depth)\n",
    "\n",
    "\n",
    "        dates_temp_pd = pd.to_datetime(dates_temp, format='%Y-%m-%d')\n",
    "        dates_do_pd = pd.to_datetime(dates_do, format='%Y-%m-%d')\n",
    "        # Find the indices where the first day of each row matches between dates_temp and dates_do\n",
    "        matching_indices_temp = []\n",
    "        matching_indices_do = []\n",
    "\n",
    "        for i, date_temp in enumerate(dates_temp_pd[:, 0]):\n",
    "            for j, date_do in enumerate(dates_do_pd[:, 0]):\n",
    "                if date_temp == date_do:\n",
    "                    matching_indices_temp.append(i)\n",
    "                    matching_indices_do.append(j)\n",
    "\n",
    "        # Now filter the arrays based on these matching indices\n",
    "        print(matching_indices_temp)\n",
    "        print(matching_indices_do)\n",
    "        # Filter the temperature data arrays based on the matching indices\n",
    "        lstm_pred_temp = lstm_pred_temp[matching_indices_temp, :]\n",
    "        filtered_obs_temp = obs_temp[matching_indices_temp, :]\n",
    "        filtered_sim_temp = sim_temp[matching_indices_temp, :]\n",
    "        filtered_dates_temp = dates_temp[matching_indices_temp, :]\n",
    "        pgfm_pred_temp = pgfm_pred_temp[matching_indices_temp, :]\n",
    "        ealstm_pred_temp = ealstm_pred_temp[matching_indices_temp, :]\n",
    "        transformer_pred_temp = transformer_pred_temp[matching_indices_temp, :]\n",
    "\n",
    "        # Filter the oxygen data arrays based on the matching indices\n",
    "        lstm_pred_do = lstm_pred_do[matching_indices_do, :]\n",
    "        filtered_obs_do = obs_do[matching_indices_do, :]\n",
    "        filtered_sim_do = sim_do[matching_indices_do, :]\n",
    "        filtered_dates_do = dates_do[matching_indices_do, :]\n",
    "        pgfm_pred_do = pgfm_pred_do[matching_indices_do, :]\n",
    "        ealstm_pred_do = ealstm_pred_do[matching_indices_do, :]\n",
    "        transformer_pred_do = transformer_pred_do[matching_indices_do, :]\n",
    "\n",
    "        do_threshold = 11\n",
    "        valid_indices = np.where(~np.isnan(filtered_obs_do) & ~np.isnan(filtered_obs_temp))\n",
    "        valid_indices_obs = np.where((~np.isnan(filtered_obs_do) & ~np.isnan(filtered_obs_temp)) & (filtered_obs_do <= do_threshold))\n",
    "        valid_indices_sim = np.where((~np.isnan(filtered_obs_do) & ~np.isnan(filtered_obs_temp)) & (filtered_sim_do <= do_threshold))\n",
    "        # Filter the data based on these valid indices\n",
    "\n",
    "        valid_do_obs = filtered_obs_do[valid_indices_obs]\n",
    "        valid_temp_obs = filtered_obs_temp[valid_indices_obs]\n",
    "\n",
    "        valid_do_pred = lstm_pred_do[valid_indices]\n",
    "        valid_temp_pred = lstm_pred_temp[valid_indices]\n",
    "\n",
    "        valid_do_sim = filtered_sim_do[valid_indices_sim] # LSTM\n",
    "        valid_temp_sim = filtered_sim_temp[valid_indices_sim]\n",
    "\n",
    "        pgfm_pred_temp = pgfm_pred_temp[valid_indices]\n",
    "        pgfm_pred_do = pgfm_pred_do[valid_indices]\n",
    "\n",
    "        ealstm_pred_temp = ealstm_pred_temp[valid_indices]\n",
    "        ealstm_pred_do = ealstm_pred_do[valid_indices]\n",
    "\n",
    "\n",
    "        transformer_pred_temp = transformer_pred_temp[valid_indices]\n",
    "        transformer_pred_do = transformer_pred_do[valid_indices]\n",
    "        # Combine the DO and temperature values for convex hull calculation\n",
    "        points_obs = np.column_stack((valid_do_obs, valid_temp_obs))\n",
    "        # Calculate the convex hull\n",
    "        hull_obs = ConvexHull(points_obs)\n",
    "\n",
    "        # Combine the DO and temperature values for convex hull calculation\n",
    "        points_sim = np.column_stack((valid_do_sim, valid_temp_sim))\n",
    "        # Calculate the convex hull\n",
    "        hull_sim = ConvexHull(points_sim)\n",
    "\n",
    "        points_pgfm = np.column_stack((pgfm_pred_do, pgfm_pred_temp))\n",
    "        # Calculate the convex hull\n",
    "        hull_pgfm = ConvexHull(points_pgfm)\n",
    "\n",
    "\n",
    "        points_lstm = np.column_stack((valid_do_pred, valid_temp_pred))\n",
    "        # Calculate the convex hull\n",
    "        hull_lstm = ConvexHull(points_lstm)\n",
    "\n",
    "        points_ealstm = np.column_stack((ealstm_pred_do, ealstm_pred_temp))\n",
    "        # Calculate the convex hull\n",
    "        hull_ealstm = ConvexHull(points_ealstm)\n",
    "\n",
    "        points_transformer = np.column_stack((transformer_pred_do, transformer_pred_temp))\n",
    "        # Calculate the convex hull\n",
    "        hull_transformer = ConvexHull(points_transformer)\n",
    "\n",
    "\n",
    "        # Plotting the data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # # Plot the observed data and its convex hull\n",
    "        plt.scatter(valid_do_obs, valid_temp_obs, alpha=0.5, label='Observed', color='blue')\n",
    "        # plt.fill(points_obs[hull_obs.vertices, 0], points_obs[hull_obs.vertices, 1], 'blue', alpha=0.2, label='')\n",
    "        # hull_obs = ConvexHull(points_obs)\n",
    "        # smooth_obs = smooth_boundary(points_obs, hull_obs, smoothing_factor=0.001)\n",
    "        # plt.plot(smooth_obs[0], smooth_obs[1], 'blue', alpha=0.5, label='Observed Boundary')\n",
    "        alpha = 0.1 \n",
    "        concave_hull, _ = alpha_shape(points_obs, alpha)\n",
    "        x, y = concave_hull.exterior.xy\n",
    "        plt.plot(x, y, color='blue', label='Observed Alpha Shape Boundary', alpha=0.5)\n",
    "\n",
    "        # Plot the simulated data\n",
    "        plt.scatter(valid_do_sim, valid_temp_sim, alpha=0.5, label='Simulated', color='red', marker='o')\n",
    "        plt.fill(points_sim[hull_sim.vertices, 0], points_sim[hull_sim.vertices, 1], 'red', alpha=0.2, label='')\n",
    "\n",
    "        # Plot the simulated data\n",
    "        plt.scatter(valid_do_pred, valid_temp_pred, alpha=0.5, label='LSTM', color='purple', marker='o')\n",
    "        plt.fill(points_lstm[hull_lstm.vertices, 0], points_lstm[hull_lstm.vertices, 1], 'purple', alpha=0.2, label='')\n",
    "\n",
    "\n",
    "        plt.scatter(pgfm_pred_do, pgfm_pred_temp, alpha=0.5, label='FMPG', color='green', marker='o')\n",
    "        plt.fill(points_pgfm[hull_pgfm.vertices, 0], points_pgfm[hull_pgfm.vertices, 1], 'green', alpha=0.2, label='')\n",
    "\n",
    "\n",
    "        # plt.scatter(ealstm_pred_do, ealstm_pred_temp, alpha=0.5, label='ealstm', color='gray', marker='o')\n",
    "        # plt.fill(points_ealstm[hull_ealstm.vertices, 0], points_ealstm[hull_ealstm.vertices, 1], 'gray', alpha=0.2, label='')\n",
    "\n",
    "        # plt.scatter(transformer_pred_do, transformer_pred_temp, alpha=0.5, label='transformer', color='orange', marker='o')\n",
    "        # plt.fill(points_transformer[hull_transformer.vertices, 0], points_transformer[hull_transformer.vertices, 1], 'orange', alpha=0.2, label='')\n",
    "\n",
    "        save_path = os.path.join('../pics/relation_2', f'{lake_id}.pdf')\n",
    "        plt.title(f'{lake_id}_index{index}_Scatter Plot of DO vs Temperature with Observed Envelope')\n",
    "        plt.xlabel('Dissolved Oxygen (DO)')\n",
    "        plt.ylabel('Temperature')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        # plt.show()\n",
    "        plt.savefig(save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing lake_id {lake_id}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
